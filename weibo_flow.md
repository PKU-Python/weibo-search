# 微博爬虫项目流程图

## 项目架构图

```mermaid
graph TD
    A[爬虫获取数据] --> B[数据管道处理]
    
    B --> C1[CSV存储]
    B --> C2[SQLite存储]
    B --> C3[MongoDB存储]
    B --> C4[MySQL存储]
    B --> D1[图片下载]
    B --> D2[视频下载]
    B --> E[数据去重]
    
    subgraph 数据存储
        C1 --> F1[CSV文件]
        C2 --> F2[SQLite数据库]
        C3 --> F3[MongoDB数据库]
        C4 --> F4[MySQL数据库]
    end
    
    subgraph 媒体文件处理
        D1 --> G1[图片文件]
        D2 --> G2[视频文件]
    end
    
    subgraph 数据去重处理
        E --> H[过滤重复微博ID]
    end
```

## 数据处理流程

```mermaid
sequenceDiagram
    participant S as 爬虫
    participant P as 数据管道
    participant D as 数据存储
    participant M as 媒体处理
    
    S->>P: 发送数据项
    P->>D: 存储数据
    P->>M: 处理媒体文件
    M-->>P: 返回处理结果
    D-->>P: 确认存储
    P-->>S: 处理完成
```

## 主要功能说明

### 1. 数据存储管道
- **CSV存储**：将数据保存为CSV格式，包含微博ID、用户信息、内容等字段
- **SQLite存储**：使用SQLite数据库存储，支持数据更新和替换
- **MongoDB存储**：使用MongoDB存储，支持文档式数据存储
- **MySQL存储**：使用MySQL数据库，支持结构化数据存储

### 2. 媒体文件处理
- **图片下载**：支持单张和多张图片的下载，自动创建目录结构
- **视频下载**：支持视频文件的下载和存储

### 3. 数据去重
- 使用集合（set）存储已处理的微博ID
- 对重复数据进行过滤，避免重复存储

### 4. 数据字段
主要包含以下字段：
- 微博ID、bid
- 用户信息（ID、昵称、认证信息等）
- 微博内容（正文、话题、@用户等）
- 互动数据（转发、评论、点赞数）
- 媒体信息（图片、视频URL）
- 其他信息（发布时间、来源、IP等）

## 项目特点
1. 支持多种数据存储方式
2. 自动处理媒体文件下载
3. 内置数据去重机制
4. 模块化设计，易于扩展
5. 完善的错误处理机制 